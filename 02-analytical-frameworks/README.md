# Analytical Frameworks

**Intelligence analysis methodologies, forecasting techniques, and structured analytic techniques**

## Directory Structure

```
02-analytical-frameworks/
├── core-methods/
│   ├── structured-analytic-techniques.md (Tier I - Priority 1) ***URGENT***
│   ├── analysis-of-competing-hypotheses.md
│   ├── key-assumptions-check.md
│   ├── diagnostic-reasoning.md
│   ├── quality-of-information.md
│   └── deception-detection.md
├── forecasting/
│   ├── probabilistic-forecasting.md
│   ├── bayesian-updating.md
│   ├── superforecasting-principles.md
│   ├── ensemble-methods.md
│   ├── reference-class-forecasting.md
│   └── scenario-planning.md
├── bias-mitigation/
│   ├── cognitive-bias-catalog.md
│   ├── debiasing-protocols.md
│   ├── red-teaming.md
│   ├── devils-advocacy.md
│   ├── team-a-team-b.md
│   └── pre-mortem-analysis.md
├── structured-techniques/
│   ├── indicators-warnings.md
│   ├── cross-impact-matrix.md
│   ├── morphological-analysis.md
│   ├── multiple-scenarios-generation.md
│   └── outside-in-thinking.md
├── quantitative-integration/
│   ├── quant-qual-fusion.md
│   ├── model-based-analysis.md
│   ├── statistical-inference.md
│   └── data-driven-insights.md
└── quality-assurance/
    ├── peer-review-protocols.md
    ├── analytic-tradecraft-standards.md
    ├── sourcing-requirements.md
    └── confidence-expression.md
```

## Mission-Critical Priority: Structured Analytic Techniques Handbook

**Status**: Tier I - URGENT DEVELOPMENT REQUIRED

This document is the **highest priority** in the entire knowledge library. It standardizes daily analytical practice across all 551 QGIA personnel and directly impacts forecast accuracy.

### Why This Matters

Currently, analytical rigor depends on:
- Individual analyst training and experience
- Institutional memory passed informally
- Ad hoc application of methods
- Inconsistent quality across teams

**With standardized SATs**:
- ✅ Consistent analytical quality
- ✅ Reduced cognitive bias impact
- ✅ Transparent reasoning for review
- ✅ Improved training efficiency
- ✅ Enhanced inter-analyst collaboration

### Structured Analytic Techniques (SATs) Framework

**Definition**: Systematic approaches to organizing and evaluating information that make reasoning transparent and reduce cognitive biases.

#### Category 1: Decomposition and Visualization

**Checklist Analysis**
- Systematic review of relevant factors
- Ensures comprehensive coverage
- Prevents overlooking important variables
- Use: Pre-analysis completeness check

**Sorting/Ranking**
- Organizing information by criteria
- Reveals patterns and priorities
- Facilitates comparison
- Use: Prioritizing threats, actors, scenarios

**Matrices (2x2, 3x3)**
- Visual representation of relationships
- Cross-tabulation of variables
- Identifies patterns and gaps
- Use: Likelihood-impact analysis, actor-capability mapping

**Network Analysis**
- Mapping relationships between entities
- Identifying key nodes and pathways
- Understanding system structure
- Use: Alliance networks, influence operations, supply chains

#### Category 2: Idea Generation

**Brainstorming**
- Unconstrained generation of alternatives
- Suspends judgment to encourage creativity
- Builds on others' ideas
- Use: Scenario generation, alternative hypotheses

**Structured Brainstorming**
- Sequential idea generation (prevents groupthink)
- Anonymous contribution options
- Facilitator ensures equal participation
- Use: Controversial topics, hierarchical teams

**Nominal Group Technique**
- Silent generation, round-robin sharing, discussion, voting
- Balances individual and group input
- Prevents dominant voices from suppressing alternatives
- Use: High-stakes decisions, diverse teams

**Morphological Analysis**
- Decompose problem into dimensions
- Generate alternatives for each dimension
- Combine to create comprehensive set of possibilities
- Use: Technology forecasting, alternative strategies

#### Category 3: Scenarios and Indicators

**Scenario Development**
- Multiple plausible futures based on key uncertainties
- Not predictions—exploratory frameworks
- Forces consideration of low-probability, high-impact events
- Use: Long-term forecasting, strategic planning

**Indicators and Warnings**
- Observable events signaling scenario progression
- Leading, lagging, and coincident indicators
- Thresholds trigger reassessment or action
- Use: Early warning systems, monitoring plans

**Cone of Plausibility**
- Visual representation of expanding uncertainty over time
- Boundaries between plausible and implausible futures
- Tracks how new information narrows or widens cone
- Use: Long-range forecasting, uncertainty visualization

#### Category 4: Hypothesis Testing

**Analysis of Competing Hypotheses (ACH)**
- Generate comprehensive set of hypotheses
- Identify evidence (consistent, inconsistent, neutral)
- Matrix of hypotheses vs. evidence
- Reject hypotheses inconsistent with evidence
- Most diagnostic evidence is what refutes, not confirms
- **This is the gold standard for complex analysis**

ACH Step-by-Step:
1. **Hypotheses**: List all reasonable explanations (usually 4-6)
2. **Evidence**: Compile significant evidence and assumptions
3. **Matrix**: Create hypothesis-evidence matrix
4. **Consistency**: Assess each cell (consistent/inconsistent/neutral)
5. **Diagnosticity**: Identify most diagnostic evidence
6. **Rejection**: Eliminate hypotheses with too many inconsistencies
7. **Conclusion**: Least inconsistent hypothesis is most likely
8. **Sensitivity**: Test conclusion against key assumptions

**Diagnostic Reasoning**
- Focus on evidence that discriminates between hypotheses
- Avoid confirming evidence—seek disconfirming tests
- Most valuable evidence rules out alternatives
- Use: Testing specific claims, attribution analysis

**Argument Mapping**
- Visual representation of reasoning chains
- Premises, inferences, conclusions
- Exposes logical gaps and unsupported leaps
- Use: Evaluating complex arguments, identifying weaknesses

#### Category 5: Challenge Analysis

**Key Assumptions Check**
- Identify assumptions underlying analysis
- Assess likelihood each assumption is correct
- Test impact if assumption is wrong
- Focus on assumptions that are both uncertain and consequential
- Use: Before finalizing major assessments

**Devil's Advocacy**
- Assign role to argue against prevailing view
- Forces articulation of counterarguments
- Identifies weaknesses in reasoning
- Use: High-confidence judgments, consensus views

**Red Team Analysis**
- Independent team challenges assumptions and conclusions
- Fresh perspective, unconstrained by original reasoning
- Seeks alternative explanations and hidden flaws
- Use: Major assessments, strategic surprises prevention

**Pre-Mortem Analysis**
- Assume failure, work backward to causes
- "Six months from now, our forecast was completely wrong. Why?"
- Surfaces risks overlooked in forward reasoning
- Use: Before committing to major forecast or recommendation

**What If? Analysis**
- Systematic exploration of contingencies
- "What if X happens? Then what?"
- Reveals vulnerabilities and opportunities
- Use: Contingency planning, resilience testing

#### Category 6: Decision Support

**Decision Matrix**
- Options vs. criteria
- Weighted scoring based on priorities
- Quantifies trade-offs
- Use: Comparing policy options, resource allocation

**Pros-Cons-Faults-Fixes**
- Structured evaluation of alternatives
- Identify both advantages and weaknesses
- Propose remedies for faults
- Use: Early-stage option evaluation

**Force Field Analysis**
- Driving forces vs. restraining forces
- Assesses momentum for change
- Identifies leverage points for influence
- Use: Political feasibility, reform prospects

## Forecasting Excellence Framework

### Superforecasting Principles (Based on Tetlock)

**1. Probabilistic Thinking**
- Avoid verbal uncertainty ("likely," "possible")
- Use precise probabilities ("65% chance")
- Update incrementally with new evidence

**2. Granular Questioning**
- Break big questions into component parts
- Estimate sub-questions, aggregate upward
- Reduces complexity, improves accuracy

**3. Outside View First**
- Begin with base rates (reference class forecasting)
- How often do events like this happen?
- Then adjust for case-specific factors (inside view)

**4. Frequent Updating**
- Small, regular updates as evidence arrives
- Avoid large swings based on single data points
- Bayesian incremental adjustment

**5. Self-Awareness**
- Track your own calibration
- Recognize personal biases
- Learn from past forecast errors

**6. Perspective-Taking**
- Consider alternative viewpoints
- What would convince you otherwise?
- Steel-man opposing arguments

**7. Error Balancing**
- Distinguish Type I (false positive) vs. Type II (false negative) error costs
- Adjust thresholds based on consequences
- Different standards for warning vs. prediction

### Bayesian Updating Protocol

**Prior → Evidence → Posterior**

\[
P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)}
\]

Where:
- \(P(H)\) = Prior probability of hypothesis
- \(P(E|H)\) = Likelihood of evidence given hypothesis
- \(P(E)\) = Overall probability of evidence
- \(P(H|E)\) = Posterior probability after evidence

**Practical Application**:
1. Assign prior probability to hypothesis
2. New evidence arrives
3. Assess likelihood ratio: \(\frac{P(E|H)}{P(E|\neg H)}\)
4. Update probability proportionally
5. New posterior becomes next prior

**Example**: "Will Country X invade Country Y in next 6 months?"
- Prior: 20% (base rate for this type of dispute)
- Evidence: Major military mobilization observed
- Likelihood ratio: 5:1 (mobilization 5x more likely if invasion planned)
- Posterior: ≈55% (updated probability)

### Ensemble Forecasting

**Wisdom of Crowds Approach**
- Aggregate multiple forecasts
- Reduces individual error
- Particularly effective when forecasters have diverse information

**Methods**:
- **Simple Average**: Equal weight to all forecasters
- **Weighted Average**: Weight by track record
- **Extremizing**: Shift consensus away from 50% (reduces overconfidence)
- **Median**: Robust to outliers

**QGIA Application**: OSIQP aggregates individual analyst forecasts with performance-weighted ensemble.

## Bias Mitigation Protocols

### Common Cognitive Biases in Intelligence Analysis

**Confirmation Bias**
- Seeking evidence that confirms existing beliefs
- **Mitigation**: ACH forces consideration of disconfirming evidence

**Anchoring**
- Over-reliance on initial information
- **Mitigation**: Generate estimate before receiving others' views

**Availability Heuristic**
- Overweighting recent/vivid events
- **Mitigation**: Reference class forecasting grounds in base rates

**Groupthink**
- Conformity pressure suppresses dissent
- **Mitigation**: Structured brainstorming, anonymous input, devil's advocacy

**Hindsight Bias**
- "I knew it all along" after event occurs
- **Mitigation**: Document reasoning in advance, track forecasts systematically

**Mirror Imaging**
- Assuming others think like us
- **Mitigation**: Cultural intelligence, red team from adversary perspective

### Organizational De-Biasing

**1. Process Interventions**
- Require ACH for major assessments
- Mandate pre-mortem before finalizing forecasts
- Red team review for strategic estimates

**2. Incentive Alignment**
- Reward accuracy, not confidence
- Track and publicize calibration metrics
- No penalty for changing mind based on evidence

**3. Cultural Norms**
- Celebrate challenges to consensus
- Normalize uncertainty expression
- Value epistemic humility

## Integration with QGIA Quantum Frameworks

### SATs → Computational Models

**ACH** → **ABCP (Adaptive Bayesian Conflict Predictor)**
- Hypotheses = scenario probability distribution
- Evidence streams update probabilities in real-time
- Automated ACH matrix generation and updating

**Scenarios** → **QSFE (Quantum Superposition Forecasting)**
- Multiple scenarios modeled simultaneously
- Quantum amplitude weighting represents probability
- Collapse upon observation (new evidence)

**Network Analysis** → **EDM (Entanglement Dynamics Mapper)**
- Alliance relationships = quantum entanglement
- Cascade effects propagate through network
- Non-linear interdependencies modeled

**Pattern Recognition** → **RPRN (Recursive Pattern Recognition)**
- Historical case matching
- Meta-patterns across feature spaces
- Analogical reasoning from precedents

## Quality Assurance Standards

### Analytic Tradecraft Checklist

**Before Analysis**:
- [ ] Question clearly defined and scoped
- [ ] Requirements from consumer understood
- [ ] Relevant background reviewed
- [ ] Appropriate SATs selected

**During Analysis**:
- [ ] Multiple hypotheses considered (not just two)
- [ ] Disconfirming evidence actively sought
- [ ] Key assumptions identified and tested
- [ ] Alternative perspectives consulted
- [ ] Quantitative data properly sourced and validated

**After Analysis**:
- [ ] Reasoning transparent and documented
- [ ] Confidence level quantified (0.00-1.00)
- [ ] Key uncertainties highlighted
- [ ] Indicators for monitoring specified
- [ ] Peer review completed
- [ ] Sourcing meets standards

### Sourcing Requirements

**Multi-Source Verification**:
- Single source = low confidence maximum
- Two independent sources = moderate confidence possible
- Three+ independent sources = high confidence possible

**Source Quality Assessment**:
- Reliability: Track record of accuracy
- Access: Direct vs. secondhand knowledge
- Motivation: Incentive to deceive?
- Corroboration: Confirms or contradicts other sources?

## Training and Certification

**New Analyst Onboarding (Week 1-2)**:
- SATs fundamentals workshop
- ACH practical exercises
- Bias awareness training
- Probabilistic forecasting basics

**Continuing Education (Quarterly)**:
- Advanced SATs applications
- Case study retrospectives
- Calibration feedback sessions
- Inter-division best practice sharing

**Certification Levels**:
- **Practitioner**: Demonstrates proficiency in core SATs
- **Advanced**: Teaches SATs to others, innovates applications
- **Master**: Develops new methods, publishes tradecraft research

## Next Steps: Priority Development

**Immediate (Next 30 Days)**:
1. Draft Structured Analytic Techniques Handbook (Tier I Priority 1)
2. Compile ACH template and worked examples
3. Create bias mitigation quick reference guide
4. Develop probabilistic forecasting tutorial

**Near-Term (60-90 Days)**:
1. Build scenario planning toolkit
2. Create indicators/warnings template library
3. Develop red teaming protocols
4. Establish peer review standards

---

**Status**: STRUCTURE ESTABLISHED | TIER I PRIORITY DOCUMENT SCOPED
**Next**: Begin SAT Handbook drafting (4-6 week timeline)
**Last Updated**: 2026-02-16